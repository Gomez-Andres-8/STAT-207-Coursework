{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e746da0e",
   "metadata": {},
   "source": [
    "# STAT 207 Homework 12 [25 points]\n",
    "\n",
    "## Regularization Models for Linear Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef820a",
   "metadata": {},
   "source": [
    "Due: Wednesday, May 1, end of day (11:59 pm CT)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d94493",
   "metadata": {},
   "source": [
    "## Imports \n",
    "\n",
    "Run the following code cell to import the necessary packages into the file.  You may import additional packages, as needed for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c92b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac088395",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "With available climate data dating back many decades and the prevalence of climate change, humans are looking to understand exactly how different features of the climate affect the temperatures globally.  For this assignment, we will look to understand how the **global temperature** fluctuates based on other environmental features.\n",
    "\n",
    "We will use various atmospheric and temperature measures over 309 months from 1983 to 2008, with the following variables:\n",
    "\n",
    "- **Year**: the observation year\n",
    "- **Month**: the observation month, recorded with numbers 1 to 12\n",
    "- **MEI**: Multivariate El Nino Southern Oscillation Index (MEI), measuring the affects of the El Nino weather pattern\n",
    "- **CO2**: atmospheric concentration of carbon dioxide (in ppmv, parts per million by volume)\n",
    "- **CH4**: atmospheric concentration of methane (in ppmv)\n",
    "- **N2O**: atmospheric concentration of nitrous oxide (in ppmv)\n",
    "- **CFC-11**: atmospheric concentration of CCl3F or trichlorofluoromethane (in ppbv, parts per billion by volume)\n",
    "- **CFC-12**: atmospheric concentration of CCl2F2 or dichlorodifluoromethane (in ppbv)\n",
    "- **TSI**: the total solar irradiance (TSI) (in W/m2), measuring the rate at which the sun's energy is deposited per unit area.\n",
    "- **Aerosols**: the mean stratospheric aerosol optical depth at 500 nm, a measure associated with volcanic activity\n",
    "- **Temp**: the difference in the average global temperature for that month (in Celsius) and a reference value\n",
    "\n",
    "The ESRL/NOAA Physical Sciences Division reports the MEI; atmospheric concentrations are measured by the ESRL/NOAA Global Monitoring Division; the SOLARIS-HEPPA project website provides the TSI; the Godard Institute for Space Studies at NASA reports the Aerosols; and the Climatic Research Unit at the University of East Anglia reports the Temp.\n",
    "\n",
    "Run the code in the cell below to read in the cleaned data for this document.  The data is saved as `df` with this code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dd805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('climate_change.csv')\n",
    "df_train = df[df['Year'] <= 2006]\n",
    "df_test = df[df['Year'] >= 2007]\n",
    "X_train = df_train.drop(['Year', 'Month', 'Temp'], axis = 1)\n",
    "X_test = df_test.drop(['Year', 'Month', 'Temp'], axis = 1)\n",
    "y_train = df_train['Temp']\n",
    "y_test = df_test['Temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01627e31",
   "metadata": {},
   "source": [
    "## 1. Summarize Data [2 points]\n",
    "\n",
    "Above, we set aside a training data.  We didn't randomly select our training and test set; instead, we imagine that we fit a model using the available data in 2006 in our training data.  We'll then use the following data from the months from 2007 and 2008 as the test set.\n",
    "\n",
    "As defined in our X_train and X_test above, our response variable for this assignment with be **Temp**.  We'll use all variables except the **Year** and **Month** as our predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a59b4a",
   "metadata": {},
   "source": [
    "**a)** First, let's explore the summary statistics between our predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9bb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ecebd44",
   "metadata": {},
   "source": [
    "**b)** Scale our predictor variables in the training data.  Then, observe the summary statistics for the variables in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1bfdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e25ba7d6",
   "metadata": {},
   "source": [
    "**c)** Now, we want to be sure that we also scale our test data according to the same process.  Apply your scaling algorithm from **part b** to the test data.  Observe the means and variances of your scaled test data.\n",
    "\n",
    "*Note*: This does not include re-fitting your scaling process.  You will re-use your scaling process from **part b**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18cb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73183356",
   "metadata": {},
   "source": [
    "## 2. Fitting A Model [1 point]\n",
    "\n",
    "Fit a LASSO model with $\\lambda = 0.06$ to the training data, including all variables except the year and month variables.  Print the coefficients for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44209de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c043d687",
   "metadata": {},
   "source": [
    "## 3. Picking a Best Model [2 points]\n",
    "\n",
    "Let's suppose that we decide to move forward with a ridge regression model.  We originally fit the model with $\\lambda = 0.06$.  Let's explore whether this value of $\\lambda$ is the best for our model.\n",
    "\n",
    "To do this, we'll explore $\\lambda$ values between 0.05 and 1 exploring by every 0.05.  We can do this with code using:\n",
    "\n",
    "`for m in range(1, 21):`\n",
    "\n",
    "`alph = m / 20`\n",
    "\n",
    "The following code sets up the folds for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val = KFold(n_splits = 10, shuffle = True, random_state = 202405)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d80c66",
   "metadata": {},
   "source": [
    "**a)** Use 10-fold cross-validation to explore the $R^2$ values for each of the $\\lambda$s as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b39474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123eea63",
   "metadata": {},
   "source": [
    "**b)** Print the $R^2$ values for each of the individual folds of your optimal $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24b2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "014839e9",
   "metadata": {},
   "source": [
    "**c)** Repeat this process for a different set of 10-folds, using a random state of your choosing.  Determine which $\\lambda$ results in the optimal mean $R^2$, similar to what you did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f79e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "637912d1",
   "metadata": {},
   "source": [
    "## 4. Evaluating Our Best Model [1.5 points]\n",
    "\n",
    "**a)** Refit the model with the optimal $\\lambda$ found in Question 3 to the full training data.  Then, print the resulting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1b557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46f50f8c",
   "metadata": {},
   "source": [
    "**b)** Calculate the $R^2$ on the test data for the model fit in **4a**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf0c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f02327ec",
   "metadata": {},
   "source": [
    "Remember to keep all your cells and hit the save icon above periodically to checkpoint (save) your results on your local computer. Once you are satisified with your results restart the kernel and run all (Kernel -> Restart & Run All). **Make sure nothing has changed**. Checkpoint and exit (File -> Save and Checkpoint + File -> Close and Halt). Follow the instructions on the Homework 12 Canvas Assignment to submit your notebook to GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
